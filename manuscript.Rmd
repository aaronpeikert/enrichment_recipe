---
title: "A recipe for extremely reproducible enrichment analysis"
author: "Mark Ziemann and Anusuiya Bora"
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    fig_width: 5
    fig_height: 5
---

<b>Alt titles:</b>

* "Enrichment analysis with gold standard reproducibility"

* "A guide to completely reproducible enrichment analysis"

Mark Ziemann<sup>1</sup>*, Anusuiya Bora<sup>2</sup>

**Affiliations**

1. Deakin University, Geelong, Australia, School of Life and Environmental Sciences.

2. Vellore Institute of Technology, Vellore, India.

(*) Corresponding author: m.ziemann@deakin.edu.au

## Abstract

asddsadasd

## Introduction

```{r,libs,echo=FALSE}

library("DiagrammeR")

```

Reproducibility is essential to the scientific enterprise by confirming the validity of new discoveries
[1](National Academies of Sciences 2019, p1).
According to a 2016 survey of *Nature* readers, 52% of respondents agreed that there was "significant
crisis" of reproducibility [2](Baker 2016).
While bioinformatics and other branches of computational research are theoretically amenable to
complete reproducibility, in reality this is rarely achieved due to lack of detail provided in methods
sections, lack of shared data and lack of code [3](Peng 2011).
Indeed even if data and code are shared, reproducibility still cannot be guaranteed due to the
differences in computing environments over time, and the availability of dependancies [4](Perkel 2020).

To address this, many articles have been written to endorse the use of "virtual machines" or
"containerisation" to control the "environment" including the operating system and dependancies
along with the research code to facilitate a high degree of reproducibility [4-16](Perkel 2020;
Stein 2010; Dudley & Butte 2010; Sandve et al, 2013; Piccolo & Frampton 2016; Grüning et al, 2014;
Lewis et al, 2016; da Veiga Leprevost et al, 2017; Kulkarni et al, 2018; Pasquier et al, 2018;
Hung et al, 2019; Brito et al, 2020; Piccolo et al, 2021).
Containers also allow for an easy installation process, as all working dependencies are shipped together
and can be installed with a single command.

In addition to shared code, data and containerisation, there are a few ways researchers can make their
work more reproducible.
Firstly, thorough documentation makes the reproducibility process a great deal easier and more accessible
to novice bioinformaticians.
Version control keeps track of code and documentation changes over time and manages the edits made by
multiple contributors.
Literate programming using Rmarkdown or Jupyter notebooks provides optimal documentation by embedding
free text explanations together with the code and outputs such as charts and tables.
Secondly, code and data can be linked. This means that the code knows the location of the the data,
avoiding any "file not found" errors.
Lastly, reanalysis can be made as simple as possible by creating a master script that executes analysis
for each figure sequentially, making the entire manuscript reproducible by executing just one command
any without any manual steps.
Taken together, computational reproducibility is a spectrum (**Figure 1**), and rests upon five key
pillars mentioned above (**Figure 2**).
Currently, bioinformatics work at the gold standard is rare, despite the availability of such tools for
over a decade.

![Figure 1. The computational research reproducibility spectrum. Creator: Altuna Akalin.](img/repro.webp "The computational research reproducibility spectrum.")

![Figure 2. The five pillars of computational reproducibility.](img/pillarsV2.png "The five pillars of computational reproducibility. .")

In this article, we focus on enrichment analysis, which is one of the most used methods in
computational biology, and involves the summarisation of omics data to reflect biological changes,
such as the detection of pathway activation in development or disease
[17,18](Slonim 2002; Khatri et al, 2012).
While enrichment analysis is undoubtedly a key method for the interpretation of large
data sets, there are concerns that inadvertant misuse of these methods leads to
unreliable results.
These potential problems include (i) the lack of correct background for over-representation tests,
(ii) lack of p-value correction for multiple testing and (iii) lack of reporting detail
[19-22](Timmons et al, 2005; Reimand et al, 2019; Wijesooriya et al, 2022; Zhao & Rhee 2023).
Without comprehensive methodological documentation and reproducibility, it isn't possible to verify
the validity of the methods and results.
We are concerned about the reliability of published enrichment analyses, as web-based and
point-and-click tools appear to be far more popular than computer script based methods for this type
of work [21](Wijesooriya et al, 2022).
Although web-based tools are convenient, they are a potential reproducibility concern.
Firstly, incomplete reporting of methods, options and parameters is common.
Secondly, algorithms and functional annotation sets undergo regular updates, and previous versions are
typically not made available hampering later reproducibility.
In some cases the entire web resource can become unavailable, and hence irreproducible due to
a phenomenon known as link decay [23](Hennessey & Ge 2013).

A small number of enrichment analysis applications have been developed to have beneficial properties
of being "containerised" and with archived historical versions [24,25](Ge et al, 2020;
Perampalam & Dick 2020).
This helps reproducibility greatly, but is not a complete solution as it lacks information about how
the input data was used and a record of any parameter selections.

A solution to this is to use containerisation to provide a scripted
workflow with prescribed links to research data, external databases and complete record of parameter
selection.
When designed correctly, these containers encapsulate bioinformatics workflows and could ensure their
computational reproducibility for decades to come with just one or a few simple commands.
There are multiple barriers to entry for such workflows including (i) the added difficulty compared to
existing point-and-click solutions; (ii) time poorness of researchers to learn new skills; and (iii)
a lack of step-by-step guides and templates aimed at beginner users.

We address this firstly by providing working templates for docker image and Rmarkdown scripts for
common transcriptome and enrichment analysis routines.
Secondly, we provide step-by-step written and video guides to help users customise these templates for
their own work, deploy the analysis, verify the results, and archive the Docker image.

However, before recommending or prescribing such workflows, it is necessary
to assess directly whether current practices are appropriate, by trying to reproduce the enrichment
analyses of previously published studies, and examining whether the conclusions of those articles
are supported or not.
In the following section we investigate the computational reproducibility of enrichment analyses
shown in a sample of 20 journal articles published in 2019.
This should provide a sound basis for recommendations.

## A systematic assessment of reproducibility in enrichment analysis

### Methods

From a list of 186 PubMed central articles using enrichment analysis that we examined previously
[5](Wijesooriya et al, 2022), we selected 20 articles that fulfilled the following criteria; (1) the
organism under study is human; (2) the tool used was DAVID Version 6.8 (Database for Annotation,
Visualization, and Integrated Discovery)[101](Huang et al, 2007); (3) the omics type was gene
expression (array or RNA-seq); and (4) that the gene list was provided in the supplementary data.
The basis for these selection criteria is that this combination represents the most common application
of enrichment analysis in our previous study, which could be reproduced without the need to
reanalyse the raw dataset from scratch.

The lists of genes were collected from the supplementary files and stored in a spreadsheet, paying
special attention to preventing gene name errors from occurring[102](Zeeberg et al, 2004).
The reproducibility analysis was performed using the respective methodologies stated in the methods
sections of the 20 articles using DAVID version 6.8 (March-May 2022).

Briefly, we used the DAVID "Analysis Wizard" and pasted in the provided gene list into the text box,
selecting this as "gene list", together with the appropriate gene identifier type.
Typically this was the official gene symbol.
The species was specified as *Homo sapiens*.
Next we clicked on the "Functional Annotation Tool" link, bringing up the "Annotation Summary Results”
page.
We followed the steps indicated in the respective papers to select appropriate gene sets investigated
in the articles such as gene ontology (biological process, molecular function), KEGG pathways, etc.
Next, the "Functional Annotation Chart" was clicked on, opening a new window with a table of
enrichment results, which were saved for future reference.

The data presented in the paper was compared with the results we obtained, recording any
discrepancies.
Additionally, the statements made in the abstract, results, and discussion sections were carefully
examined and cross-checked with our results to understand whether those assertions survive reproduction
or not.

Each article was critically evaluated and given a score of one (1) to three (3).
Articles rated 1 showed overall poor reproducibility.
For example most GO and/or KEGG terms mentioned in the results and discussion were not confirmed
upon reproduction, and the conclusions of the study were overall not supported.
Articles were rated 2 when at least 50% of the terms are observed as significant after replication,
according to the original study's significance threshold, and most conclusions were supported.
Articles were rated 3 when they showed a high level of reproducibility, with 80% or more of the terms
shown in the article observed again in reproduction, and all conclusions were supported in reproduction.

### Results and discussion

After conducting this reproduction study according to the methods described in the respective articles,
the 20 articles were classified based on the degree of reproducibility (Figure 3).
Six studies were classified as low reproducibility, while 10 were classified as medium and just three
were classified as high.
Justifications for these classifications are provided in Table 1.

```{r,barchart,fig.width=6,fig.height=5,echo=FALSE,fig.cap = "Figure 3. Examining reproducibility in a sample of 20 journal articles."}

score1 <- c("PMC6405693","PMC6425008","PMC6535219","PMC6539328","PMC6542760","PMC6561911","PMC6663624")
score2 <- c("PMC6368841","PMC6381667","PMC6463127","PMC6557785","PMC6580941","PMC6591946",
  "PMC6582306","PMC6333352","PMC6526186","PMC6607402")
score3 <- c("PMC6349697","PMC6444048","PMC6587650")
l <- list("1-low"=score1,"2-medium"=score2,"3-high"=score3)

barplot(unlist(lapply(l,length)),col="lightgray",
  xlab="reproducibility score",ylab="no. articles",
  ylim=c(0,11))

grid()
text(0.7,1:7-0.5,labels=score1)
text(1.9,1:10-0.5,labels=score2)
text(3.1,1:3-0.5,labels=score3)

pc <- unlist(lapply(l,length)) / sum(unlist(lapply(l,length))) * 100
pc2 <- paste(pc,"%",sep="")
text(c(0.7,1.9,3.1),unlist(lapply(l,length))+0.4,labels=pc2)

```

| S.No. Pubmed ID: Replication of (Table/Figure) | A. Was Replication possible? B. Were there other significant terms found which were not mentioned in the article? | Replication score and justification |
| --- | --- | --- |
| 1.PMC6349697: Figure 2C and 2D | A. Yes, however, corrected p values are different after replication. B. Yes, only BP terms were taken into account so several CC and MF significant terms were not mentioned in the paper. |  **3.** Considering top 6 BP Terms and KEGG pathways. The basis of the selection of just 6 gene ontologies and 4 KEGG pathways shown in the paper needs to be addressed when there is a higher amount of significant GOs and pathways are observed after replication. It was impossible to determine if the article utilised a background gene list or not. The steps to perform DAVID analysis could have been elaborated in the paper. The results shown in the paper are observed after replication but only 6 BP GO significant terms are shown in the paper. |
| 2.PMC6368841: Figure 3 A - D | A. Only GO Terms were the same as the paper. KEGG terms were highly inconsistent. B. Replicated KEGG Terms (using DAVID) were not mentioned in the results of the paper. Shows inconsistency due to the usage of the server. Some terms using clusterprofiler in R were mentioned. | **2.** GO results from the original manuscript is somewhat similar to reproduced analysis. The FDR values however are inconsistent. KEGG results were highly different. The list of genes as input into DAVID analysis is unclear. They should have mentioned both up and down-regulated proteins were considered. |
| 3.PMC6381667: Figure 1 and Figure 2 | A. Results are not reproducible and are highly inconsistent B. N.A. | **2.** GO terms obtained after replication showed inconsistent results compared to the results in the original article. KEGG results were similar. Better naming convention for supplementary file for 117 genes for DAVID input is necessary. GO Results are not reproducible and are highly inconsistent. |
| 4.PMC6405693: Table 1 and Table 2; Texts under “Protein-Protein Interaction Network Building and Interrelation Analysis Between Pathways” | A. Results do not match. B. N.A. | **1.** GO analysis from upregulated and downregulated proteins are less similar to the results given in the paper. The FDR values for some pathways are highly inconsistent. KEGG Analysis of all DEGs do not match at all. |
| 5.PMC6425008: Most of the tables and figures of the paper (Figure 5, 6, 7), Table 2 | A. No. B. N.A. | **1.** This paper could have done proper labelling of supplementary files as it was difficult the gene list for DAVID analysis. Lacks information on when control genes are used and when citral-affected gene lists are used. Replication of GO and KEGG analysis is not consistent with results from the paper. How were Figures 5-7 derived? The overall protocol is not so coherent. |
| 6.PMC6444048: The text under “Pathway analysis of SUVmax related genes” And Table 2 | A. Terms are the same but gene counts have been different. The DAVID results are somewhat reproducible. B. No | **3.** Gene counts in the terms significantly enriched in the “process of cell division” and “nucleoplasm” has changed. Only cell cycle is highly enriched in the replicated results, the claims of metabolic pathways and hypoxia signalling (through GSEA analysis) to be enriched are not accurate. The results claimed are somewhat similar. All the processes have different FDR values. |
| 7.PMC6463127: Table 4, Table 5, Table 6 | A. Yes but the significance differed. B. Yes, several terms from replication were not mentioned in the paper for GO Analysis. | **2.** Does not consider corrected p values. Overall, significant terms from GO analysis of up and downregulated DEGs are missing upon replication. |
| 8.PMC6535219: Figure 2 | A. Somewhat similar. B. There were many top significant terms that were not mentioned. | **1.** Narrowing/Filtering the given gene list is a required step that could have been mentioned. Many terms were not so significant anymore. There were new terms that are of top positions after replication. |
| 9.PMC6539328: Figure 1A | A. Mostly not. B. Yes, many | **1.** The significant pathways stated in the paper are not showing up once replicated. There is no clarity of the up-regulated genes used for GO and KEGG analysis. Only 21 upregulated genes are listed whereas the paper states 4831. Also, why are only upregulated genes are being used? |
| 10.PMC6542760: Figure 4 | A. No. B. Yes, many significant terms were observed. | **1.** Replication results of GO terms are not at all compliant with the results shown in the paper. |
| 11.PMC6557785: Figure 5 A-B | A. Yes, but results in paper are not significant upon replication. B. Yes | **2.** For GO terms, there are other terms that have higher numbers of genes, making them more enriched than immune-related pathways as mentioned in the paper. For KEGG Pathways, there are other pathways that are more significant and contain a higher number of genes enriched for example “Salmonella infection” that has a higher count of genes but is not mentioned in the paper. |
| 12.PMC6561911: Figure 5 a and b | A. No. B. N.A. | **1.** The enrichment analysis results are inconsistent with the results displayed in the paper. There was no KEGG analysis done |
| 13.PMC6580941: Table 1 and Table 2 | A. Yes. B. Yes! Significant terms like “nucleoplasm”, “RNA Binding”, “protein binding” are missing from the paper. | **2.** For GO analysis, the replicated results are not as significant as the GO terms shown in Tables 1 and 2 of the paper. The Gene list for input is not so clearly mentioned, it should have been labelled properly in the name of the supplemental file. P-values are completely different. |
| 14.PMC6587650: Figure 2 | A. Yes. B. Yes, som. | **3.** (Best) The GO terms results of BP, MF, CC and KEGG pathway results from the paper are compliant with replicated results. They could have mentioned why they chose the type of sorting shown in the paper to display their results. Overall, all results have been replicated. |
| 15.PMC6591946: Figure 5 c and Figure 6 a | A. Yes for GO analysis only. B. Yes for KEGG analysis | **2.** The GO term results of replication are compliant with Figure 5 c of the paper. KEGG pathway results are semi-consistent. |
| 16.PMC6663624: Table 3 and Table 4 | A. Yes. B. Yes | **1.** The top 2 significant GO terms in the paper are not significant after replication analysis is done. Other GO terms are the same as replicated results. For KEGG Analysis, some terms are more significant after replication. Eg: PD-L1 expression and PD-1 checkpoint pathway in cancer, Th1 and Th2 cell differentiation, Th17 cell differentiation were more significant after “natural killer (NK) cell-mediated cytotoxicity” KEGG Pathway. The paper is somewhat replicable. |
| 17.PMC6582306: Figure 5 | A. Partly. B. Yes, many. | **2.** The paper uses 44 sets of DEGs grouped in 4 major types. For replication, OFC Set 9 was used, DAVID GO analysis was done twice where a discrepancy of results was observed. Compared to the paper, the most significant term was missing after replication analysis was conducted. For OFC set 9, several pathways are seen after replication but only one pathway is shown in paper. This should be addressed. |
| 18.PMC6333352: Figure 7 | A. Yes. B. Yes. There was a difference in gene counts as well. | **2.** DAVID was used for KEGG Analysis: From WGCNA - Bahn - KEGG Analysis: Epstein-Barr virus infection, the pathway with the highest gene count is missing in the results shown in the paper. From NERI - BAHN - KEGG Analysis: “Pathways of neurodegeneration - multiple diseases”, “Pathways in cancer” - pathways with the highest gene count (30 and 28 respectively) are not mentioned in the paper. Other pathways are present and the paper is somewhat reproducible. |
| 19.PMC6526186: Table 1 | A. Yes. B. Yes. | **2.** The top BP GO terms from the paper are no longer significantly higher in the replicated GO results. The top 2 KEGG Pathways after replication are “Human cytomegalovirus infection” followed by “Pathways in cancer”. The p-values have changed after the results were replicated, compared to the values given in the paper. The rest of the pathways are similar to the results given in the paper. |
| 20.PMC6607402: Figure 1 A-D | A. Yes. B. Yes, many! | **2.** For GO analysis and their replication, top enriched BP, CC and MF GO terms are not mentioned. Most of the terms are mentioned in the replicated results, but different levels of enrichment. |

: Table 1. Classification and justification for each article.

Taken together, the ability to replicate DAVID enrichment analysis using the supplementary gene
lists was highly variable.
We note that DAVID 6.8 server has been replaced by DAVID 2022 server as of June 1, 2022, meaning
that is no longer possible to reproduce DAVID 6.8 analyses.

## A container-based approach to addressing reproducibility of enrichment analysis

### Implementation

We have developed a step-by-step protocol for how to conduct an extremely reproducible
enrichment analysis, which is attached as a supplementary file (Suppl Info 1), and published to
protocols.io with a permissive license.
This protocol has the features of reproducibility mentioned in **Figure 1** and **Figure 2** including
version control with git and GitHub, compute environment control using Docker, literate programming
with Rmarkdown, persistent code and data sharing with Zenodo and documentation of all of these to
empower others to reproduce the workflow.

Central to this protocol is the provision of template Dockerfile and an Rmarkdown script, which
are intended to be remixed and altered by the end user to suit the needs of their project.

The Dockerfile uses a base image from Bioconductor which should correspond to the latest available
stable release version (currently 3.16), running on R v4.2.2 and Ubuntu 22.04.
The image contains instruction for installing a few useful utilities including `nano` and `git` for
modifying scripts, and `magic-wormhole` for transfering data between computers.
It installs R packages from CRAN and Bioconductor repositories to fulfill common tasks in transcriptome
analysis such as fetching RNA-seq counts from DEE2 with `getDEE2` [201](Ziemann et al, 2019),
differential expression with `DESeq2` [202](Love & Huber, 2014),
enrichment analysis with `clusterprofiler`, `fgsea` and `mitch`
[203-205](Yu et al, 2012; Korotkevich et al, 2016; Kaspi & Ziemann 2020).
It also contains instructions to clone a github repository, which contains the scripts that run the
analytical workflow.
Lastly, it copies a gene set library from Reactome [206](Gillespie et al, 2022) with a clear version
history to guarantee provenance of the annotation data.

The Rmarkdown script called `example.Rmd` undertakes the transcriptome and enrichment analyses.
Rmarkdown allows the unification of extended descriptions, code and results into a single document,
which is becoming ubiquitous in bioinformatics and data science more generally
[207](Grolemund & Wickham 2017, p423).
The ability to provide extended descriptions is helpful for providing contextualising information about
the purpose of the work, detailed methods and interpretations derived from the analysis.
The Rmarkdown script contains code chunks that perform specific tasks including fetching an example
data set from DEE2, inspecting data quality, differential expression and two types of enrichment
analysis; over-representation analysis (ORA) and functional class scoring (FCS) (**Figure 4**).
For each enrichment analysis conducted, a checklist is provided to comply with reporting guidelines
[22](Zhao & Rhee 2023).

```{r,diagram,echo=FALSE,fig.cap = "Figure 4: Flow chart of example workflow."}

grViz("digraph flowchart {
      node [fontname = Helvetica, shape = rectangle]
      tab1 [label = '@@1']
      tab2 [label = '@@2']
      tab3 [label = '@@3']
      tab4 [label = '@@4']
      tab5 [label = '@@5']
      tab6 [label = '@@6']
      tab1 -> tab2 -> tab3 -> tab4 -> tab6;
      tab3 -> tab5 -> tab6 }
      [1]: 'Fetch RNA-seq from DEE2'
      [2]: 'Quality control'
      [3]: 'Differential expression'
      [4]: 'Over-representation analysis'
      [5]: 'Functional class scoring'
      [6]: 'Euler diagram'
")

```

To reproduce this work is relatively quick and simple, requiring six commands and approximately four
minutes to install Docker, pull the image, run the container, run the Rmarkdown script exit the container
and copy the newly created report from the container to the current working directory (Box 1).

```bash
sudo apt update && sudo apt install docker-ce -y  # 60 sec
docker pull mziemann/enrichment_recipe  # 60 sec
docker run -it --entrypoint /bin/bash mziemann/enrichment_recipe #few seconds
Rscript -e 'rmarkdown::render("example.Rmd")' # 90 sec
exit
docker cp $(docker ps -aql):/enrichment_recipe/example.html . # instant
```
<p style="text-align: center;">
*Box 1. Reproduce a transcriptome and enrichment analysis with Docker.*
</p>

### Demonstration

To demonstrate the utility of this workflow, we present the results of this example data analysis;
it is a comparison of control and 5-azacitidine-treated AML3 cell transcriptomes with RNA-seq
in triplicate [208](Lund et al, 2014).
We use this analysis to better understand the effect of DNA methylatransferase inhibitors on
genome regulation and elaborate upon previous findings by Lund et al (2014), which mainly focused on
the relationship between RNA expression and DNA methylation, but did not show results of a
transcriptome-only enrichment analysis.
Furthermore, we provide a comparison of the two most common approaches for enrichment analysis; ORA and
FCS, and give guidance for interpreting results of such tests.

For quality control the number of reads per sample was calculated, and found to be in the range of
11-16M.
Genes with fewer than 10 reads per sample on average were removed from the analysis, leaving 13,168
genes.
Differential expression analysis revealed 3,598 differentially expressed genes with FDR<0.05, with
1,672 exhibiting higher expression and 1,926 exhibiting lower expression in 5-azacytidine treated cells
(Figure 5A).
Up and down-regulated gene sets were subjected to ORA separately, using the list of
13,168 genes as the background, and gene sets from REACTOME.

With ORA, we observed 149 upregulated and 48 downregulated gene sets.
We prioritised the enrichment analysis by enrichment score, a pseudo measure for effect size,
which tends to highlight smaller and more specific gene sets undergoing more drastic differential
expression, rather than large gene sets that undergo small expression changes.
This led to the identification of upregulated pathways related to nuclear RNA export,
glucokinase regulation and G1/S DNA replication pathways; while downregulated pathways
were associated with interferon signaling, interleukin signaling, granulopoiesis and NADPH oxidase
(host defence) (Figure 5B).

After FCS, we identified 241 upregulated genesets and 155 downregulated genesets.
FCS upregulated pathways were associated with prometaphase chromosome condensation, nuclear RNA export
and defective homologous recombination repair (Figure 5C).
Downregulated pathways related to endosomal/lysosome pathway, interferon signaling and TLR/TNF signaling.

Regarding upregulated pathways, the similarity between ORA and FCS was relatively high, exhibiting a
Jaccard index of 0.54, however these method disagreed in downregulated pathways, with a Jaccard
index of only 0.27 (Figure 5D).

![Figure 5: Differential expression and enrichment analysis with the example workflow.](img/fig_example.png "Example enrichment analysis on")

## Concluding remarks

Although our reproducibility study was relatively small, there are a few key observations.

We observe that only 3/20(15%) of studies achieved a high degree of reproducibility.

A literature search identified very few studies conducted to systematically examine the reproducibility
of bioinformatics research.

There were several case studies, but the overall lack of quantitative data appears to be out of
proportion to the number of review and commentary articles recommending computational best-practices.

Ionnidis et al (2009) examined a set of 10 gene expression studies with available data published in
2005-2006, and found only two could be reproduced to a satisfactory level
(https://www.nature.com/articles/ng.295).


http://www.bioinformatics.deib.polimi.it/geco/workshop/reproducibility.pdf

In the realm of social sciences, 

Only 40-50% of social psychology studies could be reproduced, depending on how reproduction is defined
(https://plato.stanford.edu/entries/scientific-reproducibility/)


Reproducibility in the Social Sciences
(https://www.annualreviews.org/doi/abs/10.1146/annurev-soc-090221-035954)


we can conclude that just 15% of studies could be 

It is important to note that the DAVID 6.8 server has been replaced by DAVID 2022 server, starting
from June 1, 2022.
For our analysis, DAVID version 6.8 was used for replication procedures.
It was ensured that our analyses got completed by 31 May 2022.
It is no longer possible to reproduce analyses conducted in DAVID 6.8








While there have been many general guides to computatonal reproducibility in the literature,
there is a need for boilerplate code templates that researchers can quickly adapt/tweak for their own
projects.

The demand for this is expected to be huge, as there are massive numbers of published articles featuring
such analyses.
Just in 2022, there were 9,917 PubMed articles with the keywords pathway/enrichment/ontology analysis
in the title or abstract alone.

The more rigourous, well documented and reproducible these studies are, we will find less wasted
research resources and greater trust/support from the general community.

* web tool developers could provide archived versions of the tool as docker images to facilitate
reproducibility while keeping the online version up to date.

As scholars, we should be following best practice in what we do and publish.

Rather than doing the minimum amount of work to get our results published, 

Docker install in 32 seconds
Docker pull in 47 seconds


## Bibliography

1.  National Academies of Sciences, Engineering, Medicine, Policy, Global Affairs, Committee on Science, Engineering, Medicine, Public Policy, et al. Reproducibility and Replicability in Science. Washington, D.C., DC: National Academies Press; 2019.
2.  Baker M. 1,500 scientists lift the lid on reproducibility. Nature [Internet]. 2016 [cited 2023 Mar 20];533(7604):452–4. Available from: https://www.nature.com/articles/533452a
3.  Peng RD. Reproducible research in computational science. Science [Internet]. 2011;334(6060):1226–7. Available from: http://dx.doi.org/10.1126/science.1213847
4.  Perkel JM. Challenge to scientists: does your ten-year-old code still run? Nature [Internet]. 2020 [cited 2023 Mar 20];584(7822):656–8. Available from: https://www.nature.com/articles/d41586-020-02462-7
5.  Stein LD. The case for cloud computing in genome informatics. Genome Biol [Internet]. 2010;11(5):207. Available from: http://dx.doi.org/10.1186/gb-2010-11-5-207
6.  Dudley JT, Butte AJ. In silico research in the era of cloud computing. Nat Biotechnol [Internet]. 2010;28(11):1181–5. Available from: http://dx.doi.org/10.1038/nbt1110-1181
7.  Sandve GK, Nekrutenko A, Taylor J, Hovig E. Ten simple rules for reproducible computational research. PLoS Comput Biol [Internet]. 2013;9(10):e1003285. Available from: http://dx.doi.org/10.1371/journal.pcbi.1003285
8.  Piccolo SR, Frampton MB. Tools and techniques for computational reproducibility. Gigascience [Internet]. 2016;5(1). Available from: http://dx.doi.org/10.1186/s13742-016-0135-4
9.  Grüning B, Chilton J, Köster J, Dale R, Soranzo N, van den Beek M, et al. Practical computational reproducibility in the life sciences. Cell Syst [Internet]. 2018;6(6):631–5. Available from: http://dx.doi.org/10.1016/j.cels.2018.03.014
10.  Lewis J, Breeze CE, Charlesworth J, Maclaren OJ, Cooper J. Where next for the reproducibility agenda in computational biology? BMC Syst Biol [Internet]. 2016;10(1). Available from: http://dx.doi.org/10.1186/s12918-016-0288-x
11.  da Veiga Leprevost F, Grüning BA, Alves Aflitos S, Röst HL, Uszkoreit J, Barsnes H, et al. BioContainers: an open-source and community-driven framework for software standardization. Bioinformatics [Internet]. 2017;33(16):2580–2. Available from: http://dx.doi.org/10.1093/bioinformatics/btx192
12.  Pasquier T, Lau MK, Han X, Fong E, Lerner BS, Boose ER, et al. Sharing and Preserving Computational Analyses for Posterity with encapsulator. Comput Sci Eng [Internet]. 2018;20(4):111–24. Available from: https://ieeexplore.ieee.org/abstract/document/8409369
13.  Kulkarni N, Alessandrì L, Panero R, Arigoni M, Olivero M, Ferrero G, et al. Reproducible bioinformatics project: a community for reproducible bioinformatics analysis pipelines. BMC Bioinformatics [Internet]. 2018;19(Suppl 10):349. Available from: http://dx.doi.org/10.1186/s12859-018-2296-x
14.  Hung LH, Hu J, Meiss T, Ingersoll A, Lloyd W, Kristiyanto D, et al. Building containerized workflows using the BioDepot-workflow-builder. Cell Syst [Internet]. 2019;9(5):508-514.e3. Available from: http://dx.doi.org/10.1016/j.cels.2019.08.007
15.  Brito JJ, Li J, Moore JH, Greene CS, Nogoy NA, Garmire LX, et al. Recommendations to enhance rigor and reproducibility in biomedical research. Gigascience [Internet]. 2020 [cited 2023 Mar 9];9(6). Available from: https://pubmed.ncbi.nlm.nih.gov/32479592/
16.  Piccolo SR, Ence ZE, Anderson EC, Chang JT, Bild AH. Simplifying the development of portable, scalable, and reproducible workflows. Elife [Internet]. 2021;10. Available from: http://dx.doi.org/10.7554/eLife.71069
17.  Slonim DK. From patterns to pathways: gene expression data analysis comes of age. Nat Genet [Internet]. 2002 [cited 2023 Mar 3];32 Suppl(S4):502–8. Available from: https://www.nature.com/articles/ng1033z
18.  Khatri P, Sirota M, Butte AJ. Ten years of pathway analysis: current approaches and outstanding challenges. PLoS Comput Biol [Internet]. 2012 [cited 2023 Mar 3];8(2):e1002375. Available from: https://pubmed.ncbi.nlm.nih.gov/22383865/
19.  Timmons JA, Szkop KJ, Gallagher IJ. Multiple sources of bias confound functional enrichment analysis of global -omics data. Genome Biol [Internet]. 2015;16(1):186. Available from: http://dx.doi.org/10.1186/s13059-015-0761-7
20.  Reimand J, Isserlin R, Voisin V, Kucera M, Tannus-Lopes C, Rostamianfar A, et al. Pathway enrichment analysis and visualization of omics data using g:Profiler, GSEA, Cytoscape and EnrichmentMap. Nat Protoc [Internet]. 2019;14(2):482–517. Available from: http://dx.doi.org/10.1038/s41596-018-0103-9
21.  Wijesooriya K, Jadaan SA, Perera KL, Kaur T, Ziemann M. Urgent need for consistent standards in functional enrichment analysis. PLoS Comput Biol [Internet]. 2022;18(3):e1009935. Available from: http://dx.doi.org/10.1371/journal.pcbi.1009935
22.  Zhao K, Rhee SY. Interpreting omics data with pathway enrichment analysis. Trends Genet [Internet]. 2023 [cited 2023 Mar 1];0(0). Available from: https://www.cell.com/trends/genetics/fulltext/S0168-9525(23)00018-5
23.  Hennessey J, Ge S. A cross disciplinary study of link decay and the effectiveness of mitigation techniques. BMC Bioinformatics [Internet]. 2013;14 Suppl 14(S14):S5. Available from: http://dx.doi.org/10.1186/1471-2105-14-S14-S5
24.  Ge SX, Jung D, Yao R. ShinyGO: a graphical gene-set enrichment tool for animals and plants. Bioinformatics [Internet]. 2020 [cited 2023 Mar 9];36(8):2628–9. Available from: https://pubmed.ncbi.nlm.nih.gov/31882993/
25.  Perampalam P, Dick FA. BEAVR: a browser-based tool for the exploration and visualization of RNA-seq data. BMC Bioinformatics [Internet]. 2020 [cited 2023 Mar 9];21(1):221. Available from: https://pubmed.ncbi.nlm.nih.gov/32471392/


101.  Huang DW, Sherman BT, Tan Q, Collins JR, Alvord WG, Roayaei J, et al. The DAVID Gene Functional Classification Tool: a novel biological module-centric algorithm to functionally analyze large gene lists. Genome Biol [Internet]. 2007;8(9):R183. Available from: http://dx.doi.org/10.1186/gb-2007-8-9-r183
102.  Zeeberg BR, Riss J, Kane DW, Bussey KJ, Uchio E, Linehan WM, et al. Mistaken identifiers: gene name errors can be introduced inadvertently when using Excel in bioinformatics. BMC Bioinformatics [Internet]. 2004;5:80. Available from: http://dx.doi.org/10.1186/1471-2105-5-80




201.  Ziemann M, Kaspi A, El-Osta A. Digital expression explorer 2: a repository of uniformly processed RNA sequencing data. Gigascience [Internet]. 2019;8(4). Available from: http://dx.doi.org/10.1093/gigascience/giz022
202.  Love MI, Huber W, Anders S. Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biol [Internet]. 2014;15(12):550. Available from: http://dx.doi.org/10.1186/s13059-014-0550-8
203.  Yu G, Wang LG, Han Y, He QY. clusterProfiler: an R package for comparing biological themes among gene clusters. OMICS [Internet]. 2012;16(5):284–7. Available from: http://dx.doi.org/10.1089/omi.2011.0118
204.  Korotkevich G, Sukhov V, Budin N, Shpak B, Artyomov MN, Sergushichev A. Fast gene set enrichment analysis [Internet]. bioRxiv. 2016. p. 060012. Available from: http://biorxiv.org/content/early/2021/02/01/060012.abstract
205.  Kaspi A, Ziemann M. Mitch: Multi-contrast pathway enrichment for multi-omics and single-cell profiling data. BMC Genomics [Internet]. 2020;21(1):447. Available from: http://dx.doi.org/10.1186/s12864-020-06856-9
206.  Gillespie M, Jassal B, Stephan R, Milacic M, Rothfels K, Senff-Ribeiro A, et al. The reactome pathway knowledgebase 2022. Nucleic Acids Res [Internet]. 2022;50(D1):D687–92. Available from: http://dx.doi.org/10.1093/nar/gkab1028
207.  Grolemund G, Wickham H. R for Data Science. Sebastopol, CA: O’Reilly Media; 2017.
208.  Lund K, Cole JJ, VanderKraats ND, McBryan T, Pchelintsev NA, Clark W, et al. DNMT inhibitors reverse a specific signature of aberrant promoter DNA methylation and associated gene silencing in AML. Genome Biol [Internet]. 2014;15(8):406. Available from: http://dx.doi.org/10.1186/s13059-014-0406-2


## Supplementary information

Table XX: The software bundles in the example image.
R package dependancies not shown.

| Software | Version | Purpose |
| --- | --- | --- |
| Ubuntu | 22.04 | Operating System |
| R | 4.2.2 | Statistical computing language |
| nano | 6.2 | text editing |
| git | 2.34.1 | source control |
| R/kableExtra | 1.3.4 | render formatted tables |
| R/vioplot | 0.4.0 | violin charts |
| R/gplots | 3.1.3 | heatmaps |
| R/eulerr | 7.0.0 | Venn diagrams |
| BioC/getDEE2 | 1.8.0 | fetch example RNA-seq data |
| BioC/DESeq2 | 1.38.3 | differential expression |
| BioC/fgsea | 1.24.0 | functional class scoring |
| BioC/clusterProfiler | 4.6.1 | over-representation analysis |
| Bioc/mitch | 1.10.0 | multi-contrast enrichment |
