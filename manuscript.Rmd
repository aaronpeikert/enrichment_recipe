---
title: "A recipe for extremely reproducible enrichment analysis"
author: "Mark Ziemann and Anusuiya Bora"
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    fig_width: 7
    fig_height: 5
---

<b>Alt titles:</b>

* "Enrichment analysis with gold standard reproducibility"

* "A guide to completely reproducible enrichment analysis"

Mark Ziemann<sup>1</sup>*, Anusuiya Bora<sup>2</sup>

**Affiliations**

1. Deakin University, Geelong, Australia, School of Life and Environmental Sciences.

2. Vellore Institute of Technology, Vellore, India.

(*) Corresponding author: m.ziemann@deakin.edu.au

## Abstract

asddsadasd

## Introduction

```{r,libs,echo=FALSE}

library("DiagrammeR")

```


Reproducibility is essential to the scientific enterprise by confirming the validity of new discoveries
[1](National Academies of Sciences 2019, p1).
According to a 2016 survey of *Nature* readers, 52% of respondents agreed that there was "significant
crisis" of reproducibility [2](Baker 2016).
While bioinformatics and other branches of computational research are theoretically amenable to
complete reproducibility, in reality this is rarely achieved due to lack of detail provided in methods
sections, lack of shared data and lack of code [3](Peng 2011).
Indeed even if data and code are shared, reproducibility still cannot be guaranteed due to the
differences in computing environments over time, and the availability of dependancies [4](Perkel 2020).

To address this, many articles have been written to endorse the use of "virtual machines" or
"Docker containers" to encapsulate the operating system and dependancies along with the research code
to facilitate a high degree of reproducibility [4-16](Perkel 2020; Stein 2010; Dudley & Butte 2010;
Sandve et al, 2013; Piccolo & Frampton 2016; Grüning et al, 2014; Lewis et al, 2016;
da Veiga Leprevost et al, 2017; Kulkarni et al, 2018; Pasquier et al, 2018; Hung et al, 2019;
Brito et al, 2020; Piccolo et al, 2021).
Despite the availability of such tools for over a decade, bioinformatics analyses using fully
reproducible virtual machines or containers remains only a small fraction.

![Figure XX: The computational research reproducibility spectrum. Creator: Altuna Akalin.](img/repro.webp "The computational research reproducibility spectrum.")

In this article, we will focus on enrichment analysis, which is one of the most used methods in
computational biology, and involves the summarisation of omics data to reflect biological changes,
such as the detection of pathway activation in development or disease
[17,18](Slonim 2002; Khatri et al, 2012).
While enrichment analysis is undoubtedly a key method for the interpretation of large
data sets, there are concerns that inadvertant misuse of these methods leads to
unreliable results.
These potential problems include (i) the lack of correct background for over-representation tests,
(ii) lack of p-value correction for multiple testing and (iii) lack of reporting detail
[19-22](Timmons et al, 2005; Reimand et al, 2019; Wijesooriya et al, 2022; Zhao & Rhee 2023).
Without comprehensive methodological documentation and reproducibility, it isn't possible to verify
the validity of the methods and results.
We are concerned about the reliability of published enrichment analyses, as web-based and
point-and-click tools appear to be far more popular than computer script based methods for this type
of work [21](Wijesooriya et al, 2022).
Web-based tools are a potential concern, firstly because sometimes methods are not completely described,
and secondly, algorithms and functional annotation sets undergo regular updates.
These historical versions are typically not archived, which hampers later reproducibility.
In some cases the entire web resource can become unavailable, and hence irreproducible due to
a phenomenon known as link decay [23](Hennessey & Ge 2013).

A small number of enrichment analysis applications have been developed to have beneficial properties
of being "containerised" and with archived historical versions [24,25](Ge et al, 2020;
Perampalam & Dick 2020).
This helps reproducibility greatly, but is insufficient as it lacks information about how the input
data was used and a record of any parameter selections.

Therefore the most complete reproducibility solution is to use containerisation to provide a scripted
workflow with prescribed links to research data, external databases and complete record of parameter
selection.
Designed correctly, these containers could encapsulate bioinformatics workflows and ensure their
computational reproducibility for decades to come with just one or a few simple commands.
There are multiple barriers to entry for such workflows including (i) the added difficulty compared to
existing point-and-click solutions; (ii) time poorness of researchers to learn new skills; and (iii)
a lack of step-by-step guides and templates aimed at beginner users.

We address this firstly by providing working templates for docker image and Rmarkdown scripts for
common transcriptome and enrichment analysis routines.
Secondly, we provide step-by-step written and video guides to help users customise these templates for
their own work, deploy the analysis, verify the results, and archive the Docker image.

But is this extra work really necessary?
Although our previous work suggests that enrichment analyses on the whole lack reproducibility
[5](Wijesooriya et al, 2022), we lack the empirical data confirming this directly.
Therefore before recommending or prescribing Docker-based bioinformatics workflows, it is necessary
to assess directly whether current standards are appropriate, by trying to reproduce the enrichment
analyses of previously published studies, and examining whether the conclusions of those articles
are supported or not.
In the following section we investigate the computational reproducibility of enrichment analyses 
shown in a sample of 20 journal articles published in 2019.
This should provide a sound basis for recommendations.

## Methods

### A systematic assessment of reproducibility in enrichment analysis

<Anusuiya to populate>
<references to start at [101](Author Year)>
<Wanted to check how this looks in the file>
  
The selection of 20 articles from 2019 is based on the following factors:
  * “Homo sapiens” is the organism of the datasets
  * The tool used for enrichment analysis is “DAVID” (Database for Annotation, Visualization, and Integrated Discovery)
  * Ensuring that the complete gene list is available to perform replication analysis successfully. 

To keep the work available and accessible at all times, google cloud storage is used to store several types of files. A google spreadsheet is maintained to track the
progress. The sheet contains details like PMCID, type of organism, availability of gene set, usage of DAVID, and details about the utilization of the background gene
list by the authors. The Google spreadsheet is attached as supplementary file 1 named as “Anusuiya_PMC_2019”. 

The articles are searched for the dataset of dysregulated (upregulated and downregulated, either combined or separately) genes. It is important to understand how the list of specific gene lists was obtained by the researchers. This is usually mentioned in the materials and methods section of the paper. The list of genes found in the articles is stored in the spreadsheet named “Anusuiya_gene_list”. The gene list is maintained for our analysis under their respective PMCIDs. Special attention is given to detecting gene name errors that are usually in converted date formats when procured from excel sheets from the original paper. On request, the gene list file can be shared.


### A container based approach to addressing reproducibility of enrichment analysis

Infographic:

* source control

* containerisation

* literate programming

* documentation

The templates provided include the Dockerfile and an Rmarkdown-based workflow script.
These templates are intended to be altered by the end user, but here is an overview of the contents of
each.

The Dockerfile uses a base image from Bioconductor which should correspond to the latest available
stable release version (currently 3.16), running on R v4.2.2 and Ubuntu 22.04.
The image contains instruction for installing a few useful utilities including `nano` and `git` for
modifying scripts, and `magic-wormhole` for transfering data between computers.
It installs R packages from CRAN and Bioconductor repositories to fulfill common tasks in transcriptome
analysis such as fetching RNA-seq counts from DEE2 with `getDEE2` [201](Ziemann et al, 2019),
differential expression with `DESeq2` [202](Love & Huber, 2014),
enrichment analysis with `clusterprofiler`, `fgsea` and `mitch`
[203-205](Yu et al, 2012; Korotkevich et al, 2016; Kaspi & Ziemann 2020).
It also contains instructions to clone a github repository, which contains the scripts that run the
analytical workflow.
Lastly, it copies a gene set library from Reactome [206](Gillespie et al, 2022) with a clear version
history to guarantee provenance of the annotation data.

The `example_workflow.Rmd` is the Rmarkdown based script that undertakes the enrichment analysis.
Rmarkdown allows the unification of extended descriptions, code and results into a single document,
which is becoming ubiquitous in bioinformatics and data science more generally
[207](Grolemund & Wickham 2017, p423).
The ability to provide extended descriptions is helpful for providing contextualising information about
the purpose of the work, detailed methods and interpretations derived from the analysis.
The Rmarkdown script contains code chunks that perform specific tasks including fetching an example
data set from DEE2, inspecting data quality, differential expression and two types of enrichment
analysis; over-representation analysis (ORA) and functional class scoring (FCS) (**Figure XX**).
For each enrichment analysis conducted, a checklist is provided to comply with reporting guidelines
[22](Zhao & Rhee 2023).

```{r,diagram,echo=FALSE,fig.cap = "Figure XX: Flow chart of example workflow."}

grViz("digraph flowchart {
      node [fontname = Helvetica, shape = rectangle]
      tab1 [label = '@@1']
      tab2 [label = '@@2']
      tab3 [label = '@@3']
      tab4 [label = '@@4']
      tab5 [label = '@@5']
      tab6 [label = '@@6']
      tab1 -> tab2 -> tab3 -> tab4 -> tab6;
      tab3 -> tab5 -> tab6 }
      [1]: 'Fetch RNA-seq from DEE2'
      [2]: 'Quality control'
      [3]: 'Differential expression'
      [4]: 'Over-representation analysis'
      [5]: 'Functional class scoring'
      [6]: 'Euler diagram'
")

```

To demonstrate the utility of this workflow, we present the results of an example data analysis;
it is a comparison of control and 5-azacitidine-treated AML3 cell transcriptomes with RNA-seq
in triplicate [208] (Lund et al, 2014).

We use this analysis to try to understand better the effect of DNA methylatransferase inhibitors on
genome regulation and elaborate upon previous findings by Lund et al (2014), which mainly focused on
the relationship between RNA expression and DNA methylation, but did not show results of a
transcriptome-only enrichment analysis.
Furthermore, we provide a comparison of the two most common approaches for enrichment analysis; ORA and
FCS, and give guidance for interpreting results of such tests.

After fetching the data from DEE2, the number of reads per sample was confirmed to be in the range of
11-16M.
Genes with fewer than 10 reads per sample on average were removed from the analysis, leaving 13,168
genes.
Differential expression analysis revealed 3,598 differentially expressed genes with FDR<0.05, with
1,672 exhibiting higher expression and 1,926 exhibiting lower expression in 5-azacytidine treated cells
(Figure XXA).
These differentially expressed gene sets were subjected to ORA analysis separately, using the list of
13,168 genes as the background, and gene sets from REACTOME.

With ORA, we observed 149 upregulated and 48 downregulated gene sets.
We prioritised the enrichment analysis by enrichment score, a pseudo measure for effect size,
which tends to highlight smaller and more specific gene sets undergoing more drastic differential
expression, rather than large gene sets that undergo very small expression changes.
This led to the identification of upregulated pathways related to nuclear RNA export,
glucokinase regulation and G1/S DNA replication pathways; while downregulated pathways
were associated with interferon signaling, interleukin signaling, granulopoiesis and NADPH oxidase
(host defence) (Figure XXB).

After FCS, we identified 241 upregulated genesets and 155 downregulated genesets.
FCS upregulated pathways were associated with prometaphase chromosome condensation, nuclear RNA export
and defective homologous recombination repair (Figure XXC).
Downregulated pathways related to endosomal/lysosome pathway, interferon signaling and TLR/TNF signaling.

Regarding upregulated pathways, the similarity between ORA and FCS was relatively high, exhibiting a
Jaccard index of 0.54, however these method disagreed in downregulated pathways, with a Jaccard
index of only 0.27 (Figure XXD).

![Figure XX: Differential expression and enrichment analysis with the example workflow.](img/fig_example.png "Example enrichment analysis on")

## Concluding remarks

While there have been many general guides to computatonal reproducibility in the literature,
there is a need for boilerplate code templates that researchers can quickly adapt/tweak for their own
projects.

The demand for this is expected to be huge, as there are massive numbers of published articles featuring
such analyses.
Just in 2022, there were 9,917 PubMed articles with the keywords pathway/enrichment/ontology analysis
in the title or abstract alone.

The more rigourous, well documented and reproducible these studies are, we will find less wasted
research resources and greater trust/support from the general community.

## Bibliography

1.  National Academies of Sciences, Engineering, Medicine, Policy, Global Affairs, Committee on Science, Engineering, Medicine, Public Policy, et al. Reproducibility and Replicability in Science. Washington, D.C., DC: National Academies Press; 2019.
2.  Baker M. 1,500 scientists lift the lid on reproducibility. Nature [Internet]. 2016 [cited 2023 Mar 20];533(7604):452–4. Available from: https://www.nature.com/articles/533452a
3.  Peng RD. Reproducible research in computational science. Science [Internet]. 2011;334(6060):1226–7. Available from: http://dx.doi.org/10.1126/science.1213847
4.  Perkel JM. Challenge to scientists: does your ten-year-old code still run? Nature [Internet]. 2020 [cited 2023 Mar 20];584(7822):656–8. Available from: https://www.nature.com/articles/d41586-020-02462-7
5.  Stein LD. The case for cloud computing in genome informatics. Genome Biol [Internet]. 2010;11(5):207. Available from: http://dx.doi.org/10.1186/gb-2010-11-5-207
6.  Dudley JT, Butte AJ. In silico research in the era of cloud computing. Nat Biotechnol [Internet]. 2010;28(11):1181–5. Available from: http://dx.doi.org/10.1038/nbt1110-1181
7.  Sandve GK, Nekrutenko A, Taylor J, Hovig E. Ten simple rules for reproducible computational research. PLoS Comput Biol [Internet]. 2013;9(10):e1003285. Available from: http://dx.doi.org/10.1371/journal.pcbi.1003285
8.  Piccolo SR, Frampton MB. Tools and techniques for computational reproducibility. Gigascience [Internet]. 2016;5(1). Available from: http://dx.doi.org/10.1186/s13742-016-0135-4
9.  Grüning B, Chilton J, Köster J, Dale R, Soranzo N, van den Beek M, et al. Practical computational reproducibility in the life sciences. Cell Syst [Internet]. 2018;6(6):631–5. Available from: http://dx.doi.org/10.1016/j.cels.2018.03.014
10.  Lewis J, Breeze CE, Charlesworth J, Maclaren OJ, Cooper J. Where next for the reproducibility agenda in computational biology? BMC Syst Biol [Internet]. 2016;10(1). Available from: http://dx.doi.org/10.1186/s12918-016-0288-x
11.  da Veiga Leprevost F, Grüning BA, Alves Aflitos S, Röst HL, Uszkoreit J, Barsnes H, et al. BioContainers: an open-source and community-driven framework for software standardization. Bioinformatics [Internet]. 2017;33(16):2580–2. Available from: http://dx.doi.org/10.1093/bioinformatics/btx192
12.  Pasquier T, Lau MK, Han X, Fong E, Lerner BS, Boose ER, et al. Sharing and Preserving Computational Analyses for Posterity with encapsulator. Comput Sci Eng [Internet]. 2018;20(4):111–24. Available from: https://ieeexplore.ieee.org/abstract/document/8409369
13.  Kulkarni N, Alessandrì L, Panero R, Arigoni M, Olivero M, Ferrero G, et al. Reproducible bioinformatics project: a community for reproducible bioinformatics analysis pipelines. BMC Bioinformatics [Internet]. 2018;19(Suppl 10):349. Available from: http://dx.doi.org/10.1186/s12859-018-2296-x
14.  Hung LH, Hu J, Meiss T, Ingersoll A, Lloyd W, Kristiyanto D, et al. Building containerized workflows using the BioDepot-workflow-builder. Cell Syst [Internet]. 2019;9(5):508-514.e3. Available from: http://dx.doi.org/10.1016/j.cels.2019.08.007
15.  Brito JJ, Li J, Moore JH, Greene CS, Nogoy NA, Garmire LX, et al. Recommendations to enhance rigor and reproducibility in biomedical research. Gigascience [Internet]. 2020 [cited 2023 Mar 9];9(6). Available from: https://pubmed.ncbi.nlm.nih.gov/32479592/
16.  Piccolo SR, Ence ZE, Anderson EC, Chang JT, Bild AH. Simplifying the development of portable, scalable, and reproducible workflows. Elife [Internet]. 2021;10. Available from: http://dx.doi.org/10.7554/eLife.71069
17.  Slonim DK. From patterns to pathways: gene expression data analysis comes of age. Nat Genet [Internet]. 2002 [cited 2023 Mar 3];32 Suppl(S4):502–8. Available from: https://www.nature.com/articles/ng1033z
18.  Khatri P, Sirota M, Butte AJ. Ten years of pathway analysis: current approaches and outstanding challenges. PLoS Comput Biol [Internet]. 2012 [cited 2023 Mar 3];8(2):e1002375. Available from: https://pubmed.ncbi.nlm.nih.gov/22383865/
19.  Timmons JA, Szkop KJ, Gallagher IJ. Multiple sources of bias confound functional enrichment analysis of global -omics data. Genome Biol [Internet]. 2015;16(1):186. Available from: http://dx.doi.org/10.1186/s13059-015-0761-7
20.  Reimand J, Isserlin R, Voisin V, Kucera M, Tannus-Lopes C, Rostamianfar A, et al. Pathway enrichment analysis and visualization of omics data using g:Profiler, GSEA, Cytoscape and EnrichmentMap. Nat Protoc [Internet]. 2019;14(2):482–517. Available from: http://dx.doi.org/10.1038/s41596-018-0103-9
21.  Wijesooriya K, Jadaan SA, Perera KL, Kaur T, Ziemann M. Urgent need for consistent standards in functional enrichment analysis. PLoS Comput Biol [Internet]. 2022;18(3):e1009935. Available from: http://dx.doi.org/10.1371/journal.pcbi.1009935
22.  Zhao K, Rhee SY. Interpreting omics data with pathway enrichment analysis. Trends Genet [Internet]. 2023 [cited 2023 Mar 1];0(0). Available from: https://www.cell.com/trends/genetics/fulltext/S0168-9525(23)00018-5
23.  Hennessey J, Ge S. A cross disciplinary study of link decay and the effectiveness of mitigation techniques. BMC Bioinformatics [Internet]. 2013;14 Suppl 14(S14):S5. Available from: http://dx.doi.org/10.1186/1471-2105-14-S14-S5
24.  Ge SX, Jung D, Yao R. ShinyGO: a graphical gene-set enrichment tool for animals and plants. Bioinformatics [Internet]. 2020 [cited 2023 Mar 9];36(8):2628–9. Available from: https://pubmed.ncbi.nlm.nih.gov/31882993/
25.  Perampalam P, Dick FA. BEAVR: a browser-based tool for the exploration and visualization of RNA-seq data. BMC Bioinformatics [Internet]. 2020 [cited 2023 Mar 9];21(1):221. Available from: https://pubmed.ncbi.nlm.nih.gov/32471392/






201.  Ziemann M, Kaspi A, El-Osta A. Digital expression explorer 2: a repository of uniformly processed RNA sequencing data. Gigascience [Internet]. 2019;8(4). Available from: http://dx.doi.org/10.1093/gigascience/giz022
202.  Love MI, Huber W, Anders S. Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biol [Internet]. 2014;15(12):550. Available from: http://dx.doi.org/10.1186/s13059-014-0550-8
203.  Yu G, Wang LG, Han Y, He QY. clusterProfiler: an R package for comparing biological themes among gene clusters. OMICS [Internet]. 2012;16(5):284–7. Available from: http://dx.doi.org/10.1089/omi.2011.0118
204.  Korotkevich G, Sukhov V, Budin N, Shpak B, Artyomov MN, Sergushichev A. Fast gene set enrichment analysis [Internet]. bioRxiv. 2016. p. 060012. Available from: http://biorxiv.org/content/early/2021/02/01/060012.abstract
205.  Kaspi A, Ziemann M. Mitch: Multi-contrast pathway enrichment for multi-omics and single-cell profiling data. BMC Genomics [Internet]. 2020;21(1):447. Available from: http://dx.doi.org/10.1186/s12864-020-06856-9
206.  Gillespie M, Jassal B, Stephan R, Milacic M, Rothfels K, Senff-Ribeiro A, et al. The reactome pathway knowledgebase 2022. Nucleic Acids Res [Internet]. 2022;50(D1):D687–92. Available from: http://dx.doi.org/10.1093/nar/gkab1028
207.  Grolemund G, Wickham H. R for Data Science. Sebastopol, CA: O’Reilly Media; 2017.
208.  Lund K, Cole JJ, VanderKraats ND, McBryan T, Pchelintsev NA, Clark W, et al. DNMT inhibitors reverse a specific signature of aberrant promoter DNA methylation and associated gene silencing in AML. Genome Biol [Internet]. 2014;15(8):406. Available from: http://dx.doi.org/10.1186/s13059-014-0406-2


## Supplementary information

Table XX: The software bundles in the example image.
R package dependancies not shown.

| Software | Version | Purpose |
| --- | --- | --- |
| Ubuntu | 22.04 | Operating System |
| R | 4.2.2 | Statistical computing language |
| nano | 6.2 | text editing |
| git | 2.34.1 | source control |
| R/kableExtra | 1.3.4 | render formatted tables |
| R/vioplot | 0.4.0 | violin charts |
| R/gplots | 3.1.3 | heatmaps |
| R/eulerr | 7.0.0 | Venn diagrams |
| BioC/getDEE2 | 1.8.0 | fetch example RNA-seq data |
| BioC/DESeq2 | 1.38.3 | differential expression |
| BioC/fgsea | 1.24.0 | functional class scoring |
| BioC/clusterProfiler | 4.6.1 | over-representation analysis |
| Bioc/mitch | 1.10.0 | multi-contrast enrichment |
