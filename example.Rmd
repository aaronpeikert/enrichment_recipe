---
title: "Enrichment analysis with gold standard reproducibility."
author: "Mark Ziemann & Anusuiya Bora"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    fig_width: 7
    fig_height: 7
theme: cosmo
---

Source: https://github.com/markziemann/udocker_r_example

Alt titles:

* "Recipes for extremely reproducible enrichment analysis"

## Intro

Previously my team have written about methodological problems in enrichment analysis.
These include statistical problems, like lack of FDR correction, lack of correct background
 and poor reporting of methodological details (Wijesooriya et al, 2022).

Therefore there is a need for community-agreed guidelines for conducting and presenting
enrichment analysis work, which is something that has been noted by others
(Timmons et al, 2015; Reimand et al 2019), but has only recently been addressed (Zhao & Rhee 2023).

The purpose of this work is to offer a postive examplar of an enrichment analysis
that fills all criteria:

1. Statistically rigourous.

2. Well documented in the manuscript and public code.

3. Maximally reproducible.

While rigour and good documentation are features of enrichment analyses in high quality specialist
genomics journals, reproducibility remains a distinct weakness.

When trying to reproduce or replicate the work of others we are often frustrated by
the unavailability of input data, of functional annotations, of code, and full descriptions
of results.

For example, while conducting a replication study of 20 journal articles, we found that
one of the most frequently used web-tools, DAVID bioinformatics, was going to move from
version 6.7 to version 6.8, with no option to continue using v6.7.

Changes such as these mean that the results of many journal articles can no longer be
independently replicated, only a couple of years after original publication.

As time passes and software versions update, it will become ever more difficult to replicate
previous analyses.
This means that it will be impossible to audit many research articles if those findings come
under question.

Although it doesn't need to be this way due to the precise nature of modern computers and software.
In order for bioinformatics analysis to be 100% reproducible requires a few key elements.
These are:

* Input data

* Set of instructions (analysis code).

* Operating system

With these things working together, it is possible for a data analysis workflow to be 100%
replicable and auditable for many years into the future.

To achieve this requires some planning:

1. Input data needs to be deposited to a public and persistent location.

2. Analysis code packaged in a working Docker container.

A Docker container is a minimal operating system that has the necessary software to complete a task.
Docker is used extensively in web development, to rapidly set up many modular services into
full stacks of functionality.
For example using Docker containers, a website front end and back end can be set up once, and then
deployed at huge scale (eg thousands of instances) with minimal work involved.

In addition, Docker containers ensure consistent behaviour across different types of computing
infrastructure, so it doesn't matter whether the container is run on a linux workstation,
desktop windows PC or cloud server, the end results should be identical.

While there have been many general guides to computatonal reproducibility in the literature,
there is a need for boilerplate code templates that researchers can quickly adapt/tweak for their own
projects.

The demand for this is expected to be huge, as there are massive numbers of published articles featuring
such analyses.
Just in 2022, there were 9,917 PubMed articles with the keywords pathway/enrichment/ontology analysis
in the title or abstract alone.

The more rigourous, well documented and reproducible these studies are, we will find less wasted
research resources and greater trust/support from the general community.

## Data set being analysed 

For this guide I will be using bulk RNA-seq data from a previous study, which is
deposited at NCBI GEO and SRA under accession numbers: GSE55123 and SRP038101 (Lund et al, 2014).
The experiment is designed to investigate the effect of Azacitidine treatment on AML3 cells.

```{r,libs}

suppressPackageStartupMessages({
  library("getDEE2")
  library("DESeq2")
  library("kableExtra")
  library("vioplot")
  library("clusterProfiler")
  library("eulerr")
})

```

The raw data have been processed by the DEE2 project, and the summary gene expression counts are
available at the dee2.io website, and programmatically with the getDEE2 bioconductor package
(Ziemann et al, 2019).

```{r,fetch}

mdat <- getDEE2Metadata("hsapiens")

# get sample sheet
ss <- subset(mdat,SRP_accession=="SRP038101")

# fetch the whole set of RNA-seq data
x <- getDEE2("hsapiens",ss$SRR_accession , metadata=mdat, legacy=TRUE)
mx <- x$GeneCounts
rownames(mx) <- paste(rownames(mx),x$GeneInfo$GeneSymbol)
dim(mx)

# aza no filtering
ss$trt <- grepl("Treated",ss$Experiment_title)

ss %>%
  kbl(caption="sample sheet for Aza treatment in AML3 cells") %>%
  kable_paper("hover", full_width = F)

```

## Analysis of read counts

Although I know this data set is good as I was involved in the project,
it is a good idea to show at least the number of reads for each sample.

```{r,counts1}

par(mar=c(5,7,5,1))
barplot(rev(colSums(mx)),horiz=TRUE,las=1,main="number of reads per sample in SRP038101")

```

Now we can have a look at the read count distribution for one of the samples.

```{r,dist1}

# look at the distribution of counts
l <- lapply(1:ncol(mx),function(i) log10( mx[,i] +1 ))
names(l) <- colnames(mx)
l <- rev(l)

hist(l[[6]],main="Distribution of read counts in SRR1171523",
  xlab="log10(readcounts+1)",breaks=30)

abline(v=1,col="red",lty=2)

```

We can see that most genes have a very low read count, consistent
with most genes being undetectable in any sample.

Based on this typical distribution of read counts, I would consider
any gene with fewer than 10 reads as not detected.
This could be considered a strict detection threshold.
Setting a strict threshold like this could be helpful in selecting
genes that are likely to validate with qRT-PCR.

I will run DESeq2 with and without this threshold to see how
it impacts the results.

## Differential expression analysis with and without filtering

To see whether this has any effect on downstream analysis, DESeq2 will
be run on the same dataset without any filtering, with light filtering and with
strict filtering.

Here I define light filter threshold as the lowest baseline expression level that
DE genes start to appear.
I know this contrast will yield thousands of DE genes, so this is a reasonable
way to set the detection threshold.
The DE genes with lowest baseline expression showed mean read counts of about 2.

```{r,de1}

# DESeq2 without any fitering
dds <- DESeqDataSetFromMatrix(countData = mx , colData = ss, design = ~ trt )
res <- DESeq(dds)
z <- results(res)
vsd <- vst(dds, blind=FALSE)
zz <- cbind(as.data.frame(z),mx)
de <- as.data.frame(zz[order(zz$pvalue),])

sig <- subset(de,padj<0.05)

head(de,10) %>%
  kbl(caption="Top DE genes for Aza treatment (unfiltered)") %>%
  kable_paper("hover", full_width = F)

DET=nrow(mx)
NSIG=nrow(sig)
NUP=nrow(subset(sig,log2FoldChange>0))
NDN=nrow(subset(sig,log2FoldChange<0))

HEADER=paste(DET,"genes included;",NSIG,"w/FDR<0.05;",NUP,"up;",NDN,"down")

plot(log10(de$baseMean) ,de$log2FoldChange,
  cex=0.6,pch=19,col="darkgray",
  main="no detection filter",
  xlab="log10(basemean)",ylab="log2(fold change)")

points(log10(sig$baseMean) ,sig$log2FoldChange,
  cex=0.6,pch=19,col="red")

mtext(HEADER)

abline(v=1,lty=2)

deup <- rownames(subset(de,padj<=0.05 & log2FoldChange>0))
deup <- unique(sapply(strsplit(deup," "),"[[",2))

dedn <- rownames(subset(de,padj<=0.05 & log2FoldChange<0))
dedn <- unique(sapply(strsplit(dedn," "),"[[",2))

all <- rownames(de)
all <- unique(sapply(strsplit(all," "),"[[",2))

```

look at the lowest basemean genes

```{r,low}

sig <- sig[order(sig$baseMean),]

head(sig,10) %>%
  kbl(caption="lowest basemean genes") %>%
  kable_paper("hover", full_width = F)

```

The counts look quite low.
Not sure that these DEGs could be validated with qRT-PCR.

## Now run DESeq2 with filtering

```{r,de2}

mxf <- mx[which(rowMeans(mx)>=10),]
dim(mxf)
dds <- DESeqDataSetFromMatrix(countData = mxf , colData = ss, design = ~ trt )
res <- DESeq(dds)
z <- results(res)
vsd <- vst(dds, blind=FALSE)
zz <-cbind(as.data.frame(z),mxf)
def <-as.data.frame(zz[order(zz$pvalue),])

head(def,10) %>%
  kbl(caption="Top DE genes for Aza treatment (filtered)") %>%
  kable_paper("hover", full_width = F)

sigf <- subset(def,padj<=0.05)

DET=nrow(mxf)
NSIG=nrow(sigf)
NUP=nrow(subset(sigf,log2FoldChange>0))
NDN=nrow(subset(sigf,log2FoldChange<0))

HEADER=paste(DET,"detected genes;",NSIG,"w/FDR<0.05;",NUP,"up;",NDN,"down")

plot(log10(def$baseMean) ,def$log2FoldChange,
  cex=0.6,pch=19,col="darkgray",
  main="strict filter",
  xlab="log10(basemean)",ylab="log2(fold change)")

points(log10(sigf$baseMean) ,sigf$log2FoldChange,
  cex=0.6,pch=19,col="red")

mtext(HEADER)

defup <- rownames(subset(def,padj<=0.05 & log2FoldChange>0))
defup <- unique(sapply(strsplit(defup," "),"[[",2))

defdn <- rownames(subset(def,padj<=0.05 & log2FoldChange<0))
defdn <- unique(sapply(strsplit(defdn," "),"[[",2))

bg <- rownames(def)
bg <- unique(sapply(strsplit(bg," "),"[[",2))

```

## Now run ORA based enrichment analysis

I will run enrichment analysis using the correct correct background list,
and compare the results to the incorrect whole genome background.

```{r,gs}

if (! file.exists("ReactomePathways.gmt")) {
  download.file("https://reactome.org/download/current/ReactomePathways.gmt.zip", 
    destfile="ReactomePathways.gmt.zip")
  unzip("ReactomePathways.gmt.zip")
}

genesets2 <- read.gmt("ReactomePathways.gmt")

```

### ORA with correct background list.

Firstly with the upregulated genes

```{r,ora2up}

ora2_up <- as.data.frame(enricher(gene = defup ,
  universe = bg,  maxGSSize = 5000, TERM2GENE = genesets2,
  pAdjustMethod="fdr",  pvalueCutoff = 1, qvalueCutoff = 1  ))

ora2_up$geneID <- NULL
ora2_up <- subset(ora2_up,p.adjust<0.05 & Count >=10)
ora2_ups <- rownames(ora2_up)

gr <- as.numeric(sapply(strsplit(ora2_up$GeneRatio,"/"),"[[",1)) /
  as.numeric(sapply(strsplit(ora2_up$GeneRatio,"/"),"[[",2))

br <- as.numeric(sapply(strsplit(ora2_up$BgRatio,"/"),"[[",1)) /
  as.numeric(sapply(strsplit(ora2_up$BgRatio,"/"),"[[",2))

ora2_up$es <- gr/br
ora2_up <- ora2_up[order(-ora2_up$es),]
ora2_up$Description=NULL

head(ora2_up) %>%
  kbl(row.names = FALSE, caption="Top upregulated pathways in Aza treatment (filtered)") %>%
  kable_paper("hover", full_width = F)

topup2 <- rev(head(ora2_up$es,20))
names(topup2) <- rev(head(ora2_up$ID,20))

```

Now with the downregulated genes

```{r,ora2dn}

ora2_dn <- as.data.frame(enricher(gene = defdn ,
  universe = bg,  maxGSSize = 5000, TERM2GENE = genesets2,
  pAdjustMethod="fdr",  pvalueCutoff = 1, qvalueCutoff = 1  ))

ora2_dn$geneID <- NULL
ora2_dn <- subset(ora2_dn,p.adjust<0.05 & Count >=10)
ora2_dns <- rownames(ora2_dn)

gr <- as.numeric(sapply(strsplit(ora2_dn$GeneRatio,"/"),"[[",1)) /
  as.numeric(sapply(strsplit(ora2_dn$GeneRatio,"/"),"[[",2))

br <- as.numeric(sapply(strsplit(ora2_dn$BgRatio,"/"),"[[",1)) /
  as.numeric(sapply(strsplit(ora2_dn$BgRatio,"/"),"[[",2))

ora2_dn$es <- gr/br
ora2_dn <- ora2_dn[order(-ora2_dn$es),]
ora2_dn$Description=NULL

head(ora2_dn) %>%
  kbl(row.names = FALSE, caption="Top downregulated pathways in Aza treatment (filtered)") %>%
  kable_paper("hover", full_width = F)

topdn2 <- head(ora2_dn$es,20)
names(topdn2) <- head(ora2_dn$ID,20)

```

Make a barplot

```{r,topbarplot2}

par(mar=c(5,20,5,1))

cols <- c(rep("blue",20),rep("red",20))

barplot(c(topdn2,topup2),
  horiz=TRUE,las=1,cex.names=0.65,col=cols,
  main="top DE Reactomes",
  xlab="ES")

mtext("correct background")

```

### ORA with whole genome background list.

Firstly with the upregulated genes

```{r,ora1up}

ora1_up <- as.data.frame(enricher(gene = defup ,
  universe = all,  maxGSSize = 5000, TERM2GENE = genesets2,
  pAdjustMethod="fdr",  pvalueCutoff = 1, qvalueCutoff = 1  ))

ora1_up$geneID <- NULL
ora1_up <- subset(ora1_up,p.adjust<0.05 & Count >=10)
ora1_ups <- rownames(ora1_up)

gr <- as.numeric(sapply(strsplit(ora1_up$GeneRatio,"/"),"[[",1)) /
  as.numeric(sapply(strsplit(ora1_up$GeneRatio,"/"),"[[",2))

br <- as.numeric(sapply(strsplit(ora1_up$BgRatio,"/"),"[[",1)) /
  as.numeric(sapply(strsplit(ora1_up$BgRatio,"/"),"[[",2))

ora1_up$es <- gr/br
ora1_up <- ora1_up[order(-ora1_up$es),]
ora1_up$Description=NULL

head(ora1_up) %>%
  kbl(row.names = FALSE, caption="Top upregulated pathways in Aza treatment (unfiltered)") %>%
  kable_paper("hover", full_width = F)

topup1 <- rev(head(ora1_up$es,20))
names(topup1) <- rev(head(ora1_up$ID,20))

```

Now with the downregulated genes

```{r,ora1dn}

ora1_dn <- as.data.frame(enricher(gene = defdn ,
  universe = all,  maxGSSize = 5000, TERM2GENE = genesets2,
  pAdjustMethod="fdr",  pvalueCutoff = 1, qvalueCutoff = 1  ))

ora1_dn$geneID <- NULL
ora1_dn <- subset(ora1_dn,p.adjust<0.05 & Count >=10)
ora1_dns <- rownames(ora1_dn)

gr <- as.numeric(sapply(strsplit(ora1_dn$GeneRatio,"/"),"[[",1)) /
  as.numeric(sapply(strsplit(ora1_dn$GeneRatio,"/"),"[[",2))

br <- as.numeric(sapply(strsplit(ora1_dn$BgRatio,"/"),"[[",1)) /
  as.numeric(sapply(strsplit(ora1_dn$BgRatio,"/"),"[[",2))

ora1_dn$es <- gr/br
ora1_dn <- ora1_dn[order(-ora1_dn$es),]
ora1_dn$Description=NULL

head(ora1_dn) %>%
  kbl(row.names = FALSE, caption="Top downregulated pathways in Aza treatment (unfiltered)") %>%
  kable_paper("hover", full_width = F)

topdn1 <- head(ora1_dn$es,20)
names(topdn1) <- head(ora1_dn$ID,20)

```

Make a barplot

```{r,topbarplot1}

par(mar=c(5,20,5,1))

cols <- c(rep("blue",20),rep("red",20))

barplot(c(topdn1,topup1),
  horiz=TRUE,las=1,cex.names=0.65,col=cols,
  main="top DE Reactomes",
  xlab="ES")

mtext("whole genome background")

```


## Compare pathway results

```{r,venn1,fig.width=6,fig.height=6}

v1 <- list("correct up"=ora2_ups, "wg up"=ora1_ups)

v2 <- list("correct dn"=ora2_dns, "wg dn"=ora1_dns)

par(mar=c(10,10,10,10))

par(mfrow=c(2,1))
plot(euler(v1),quantities = TRUE)
plot(euler(v2),quantities = TRUE)

```

Jaccard index

```{r,jaccard}

jaccard <- function(a, b) {
    intersection = length(intersect(a, b))
    union = length(a) + length(b) - intersection
    return (intersection/union)
}

correct <- c(ora2_ups,ora2_dns)
incorrect <- c(ora1_ups,ora1_dns)

jaccard(correct,incorrect)

```

## Session information

For reproducibility

<br><details><summary><b>Click HERE to show session info</b></summary><br><p>

```{r,session}

sessionInfo()

```

</details>

## References


